# Technical Documentation

This document provides detailed technical information about the E-commerce Sales Generator implementation, behavior, and configuration.

## Order Lifecycle Behavior

### Realistic Order Progression

Orders follow a **realistic lifecycle progression**:
```
pending → confirmed → processing → shipped
```

- All new orders start with `pending` status
- Orders automatically progress through each stage based on realistic time intervals
- Each status change generates a new JSON event with updated timestamp
- Mimics real-world e-commerce order processing
- Orders are tracked in memory until they reach `shipped` status

**Status Transition Times:**
- `pending` → `confirmed`: 10-30 seconds
- `confirmed` → `processing`: 15-45 seconds  
- `processing` → `shipped`: 20-60 seconds

### Order Lifecycle Management

The system maintains an in-memory tracking system for active orders:
- New orders are added to the active orders pool
- Background thread checks for orders ready to transition
- Status updates generate new JSON events with same `order_id`
- Orders are removed from tracking once they reach `shipped` status
- Manual stop leaves orders in their current status (incomplete lifecycle)

## Data Structure and Schema

### Complete Sale Object

Each sale includes the following fields:

| Field | Type | Description |
|-------|------|-------------|
| `order_id` | String | Unique order identifier (format: ORD-XXXXXXXX) |
| `timestamp` | String | ISO format timestamp (UTC) |
| `product_id` | String | Product identifier (format: PROD-XXX) |
| `product_name` | String | Human-readable product name |
| `quantity` | Integer | Number of items (range: 1-5) |
| `price` | Float | Unit price per item |
| `total` | Float | Total amount (quantity × price) |
| `customer_id` | String | Customer identifier (format: CUST-XXXXXX) |
| `customer_email` | String | Customer email address (generated by Faker) |
| `payment_method` | String | Payment method used |
| `shipping_address` | Object | Complete shipping address |
| `status` | String | Current order status |

### Payment Methods

Available payment methods:
- `credit_card`
- `debit_card`
- `paypal`
- `apple_pay`
- `google_pay`
- `bank_transfer`

### Shipping Address Structure

```json
{
  "street": "String (generated by Faker)",
  "city": "String (generated by Faker)",
  "state": "String (2-letter state code)",
  "zip_code": "String (5-digit ZIP)",
  "country": "String (ISO 3-letter country code)"
}
```

## Example Output

### New Order (always starts with "pending")
```json
{
  "order_id": "ORD-93239605",
  "timestamp": "2025-11-09T15:55:40.669190Z",
  "product_id": "PROD-004",
  "product_name": "USB-C Cable",
  "quantity": 3,
  "price": 11.16,
  "total": 33.48,
  "customer_id": "CUST-968801",
  "customer_email": "campbellmichael@example.org",
  "payment_method": "bank_transfer",
  "shipping_address": {
    "street": "40772 Amy Parks",
    "city": "New Bobbyland",
    "state": "CO",
    "zip_code": "00537",
    "country": "PLW"
  },
  "status": "pending"
}
```

### Status Update (same order, now "confirmed")
```json
{
  "order_id": "ORD-93239605",
  "timestamp": "2025-11-09T15:55:52.623322Z",
  "product_id": "PROD-004",
  "product_name": "USB-C Cable",
  "quantity": 3,
  "price": 11.16,
  "total": 33.48,
  "customer_id": "CUST-968801",
  "customer_email": "campbellmichael@example.org",
  "payment_method": "bank_transfer",
  "shipping_address": {
    "street": "40772 Amy Parks",
    "city": "New Bobbyland",
    "state": "CO",
    "zip_code": "00537",
    "country": "PLW"
  },
  "status": "confirmed"
}
```

The order will continue to progress through "processing" and finally "shipped".

## Product Catalog

The generator includes 15 different products across various categories:

**Electronics:**
- Wireless Headphones
- Smart Watch
- Webcam HD
- 4K Monitor

**Computer Accessories:**
- Mechanical Keyboard
- Wireless Mouse
- USB-C Cable
- Laptop Stand

**Mobile Accessories:**
- Phone Case
- Portable Charger

**Office Supplies:**
- Desk Organizer
- Desk Lamp

**Audio Equipment:**
- Bluetooth Speaker

Each product has:
- Unique product ID (PROD-001 through PROD-015)
- Product name
- Price range varies by category

## Kafka Configuration

### Message Format

Each event is sent to Kafka with:
- **Key**: `order_id` (enables proper partitioning and ordering)
- **Value**: Complete JSON event (serialized as UTF-8)

### Producer Settings

The Kafka producer is configured with reliability in mind:

```python
{
    'acks': 'all',  # Wait for all replicas to acknowledge
    'retries': 3,   # Retry failed sends up to 3 times
    'max_in_flight_requests_per_connection': 1  # Ensures ordering
}
```

**Configuration Explanation:**
- `acks='all'`: Ensures maximum durability by waiting for all in-sync replicas
- `retries=3`: Automatically retries failed sends
- `max_in_flight_requests_per_connection=1`: Maintains message ordering even with retries

### Topic Partitioning

Using `order_id` as the key ensures:
- Orders with the same ID always go to the same partition
- Status updates maintain order within a partition
- Consumers can rely on sequential status progression per order

## Statistics and Monitoring

At the end of execution, the generator displays:

- **Total new orders created**: Count of initial orders generated
- **Total status updates**: Count of status transitions
- **Total orders shipped**: Count of orders that completed full lifecycle
- **Active orders**: Orders still in pipeline when stopped
- **Average rate**: New orders per minute

Example output:
```
=== Final Statistics ===
Total new orders created: 45
Total status updates (transitions): 132
Total orders shipped (completed): 38
Active orders (still in pipeline): 7
Average rate: 9.0 new orders per minute
```

## Integration Examples

### Apache Spark Structured Streaming

Read from Kafka in real-time:

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("EcommerceSales").getOrCreate()

df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "ecommerce-sales") \
    .load()

# Parse JSON and process
from pyspark.sql.functions import from_json, col
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType

schema = StructType([
    StructField("order_id", StringType()),
    StructField("timestamp", StringType()),
    StructField("status", StringType()),
    StructField("total", FloatType()),
    # ... add other fields
])

parsed_df = df.select(
    from_json(col("value").cast("string"), schema).alias("data")
).select("data.*")

query = parsed_df.writeStream \
    .outputMode("append") \
    .format("console") \
    .start()

query.awaitTermination()
```

### Apache Spark Batch

Read historical data from Kafka:

```python
df = spark.read \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "ecommerce-sales") \
    .option("startingOffsets", "earliest") \
    .option("endingOffsets", "latest") \
    .load()

# Process the batch data
parsed_df = df.select(
    from_json(col("value").cast("string"), schema).alias("data")
).select("data.*")

# Example: Calculate total sales by status
sales_by_status = parsed_df.groupBy("status") \
    .agg({"total": "sum"}) \
    .show()
```

### Python Consumer

Simple Python consumer using kafka-python:

```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'ecommerce-sales',
    bootstrap_servers='localhost:9092',
    value_deserializer=lambda m: json.loads(m.decode('utf-8')),
    auto_offset_reset='earliest'
)

for message in consumer:
    sale = message.value
    print(f"Order {sale['order_id']}: {sale['status']} - ${sale['total']}")
```

## Output Modes

The generator supports multiple output configurations:

1. **Console Only** (default)
   - Prints JSON to stdout
   - Best for testing and development
   - Can be redirected to file: `python sales_generator.py > sales.json`

2. **Kafka Only**
   - Sends events to Kafka topic
   - Console output disabled by default for performance
   - Use `--kafka-bootstrap-servers` and `--kafka-topic` flags

3. **Both Kafka and Console**
   - Sends to Kafka AND prints to console
   - Add `--output-console` flag
   - Useful for debugging Kafka integration

4. **File Output** (via redirect)
   - Redirect console output to file
   - Creates newline-delimited JSON
   - Can be processed line-by-line

## Performance Considerations

### Timing Configuration

Adjust these parameters based on your needs:

- `--min-delay` and `--max-delay`: Control order generation rate
  - Lower values = higher throughput
  - Higher values = more realistic spacing

- `--duration`: Total runtime in minutes
  - Default: 5 minutes
  - Set to high value for continuous generation

### Resource Usage

- **Memory**: Grows with active orders (typically <100MB)
- **CPU**: Minimal (<5% on modern systems)
- **Network**: ~1-2KB per event (varies with Kafka configuration)

### Kafka Throughput

With default settings:
- ~10-60 orders per minute (new + status updates)
- Each order generates 4 events (1 new + 3 status updates)
- Peak throughput: ~240 events/minute

## Troubleshooting

### Common Issues

**Kafka Connection Errors:**
- Verify Kafka is running: `python kafka_native_manager.py status`
- Check bootstrap servers address
- Ensure topic exists: `python kafka_native_manager.py list-topics`

**No Events Generated:**
- Check duration hasn't expired
- Verify no Python errors in console
- Try with console output to see events: `--output-console`

**Order Status Not Progressing:**
- This is normal behavior if you stop the generator early
- Orders need time to progress through all stages
- Minimum time for full lifecycle: ~45 seconds

### Debug Mode

Enable verbose output by modifying the script:
- Add print statements to track order transitions
- Monitor active_orders dictionary size
- Check thread execution for status updates

